name: Generate NOTICE (matrix + ScanCode) fix

on:
  workflow_dispatch:
    inputs:
      sbom_paths:
        description: "Comma-separated SBOM JSON paths (SPDX or CycloneDX)"
        required: true
        default: "sboms/spdx-lite.json,sboms/cyclonedx.json"
      notice_title:
        description: "Title for NOTICE.md"
        required: false
        default: "Open Source Notices"
  push:
    branches: [ main, master ]
    paths:
      - "sboms/**/*.json"
      - "sbom*.json"

jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      matrix_json: ${{ steps.mk.outputs.matrix_json }}
      title:       ${{ steps.mk.outputs.title }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install parsers
        run: |
          python -m pip install --upgrade pip
          pip install requests packaging cyclonedx-python-lib spdx-tools

      - name: Build matrix from SBOMs (with safe artifact names)
        id: mk
        run: |
          python - <<'PY'
          import json, os, re
          NOASSERT={"NOASSERTION","NONE","",None}
          def norm(s):
              if s is None: return None
              s=str(s).strip()
              return None if (not s or s.upper() in NOASSERT) else " ".join(s.split())
          def detect(doc):
              if isinstance(doc, dict):
                  if doc.get("bomFormat")=="CycloneDX" or "components" in doc: return "cdx"
                  if doc.get("spdxVersion") or doc.get("SPDXID") or "packages" in doc or "files" in doc: return "spdx"
              return "unknown"
          def parse_spdx(doc):
              res=[]
              for p in doc.get("packages") or []:
                  name=norm(p.get("name"))
                  if not name: continue
                  version=norm(p.get("versionInfo"))
                  lic=norm(p.get("licenseConcluded")) or norm(p.get("licenseDeclared"))
                  if not lic:
                      infos=p.get("licenseInfoFromFiles") or []
                      toks=sorted(set([norm(x) for x in infos if norm(x)]))
                      lic=" AND ".join(toks) if toks else None
                  homepage=norm(p.get("homepage"))
                  dl=norm(p.get("downloadLocation"))
                  url=dl or homepage
                  purl=None
                  for ref in p.get("externalRefs") or []:
                      rtype=(ref.get("referenceType") or "").lower()
                      loc=norm(ref.get("referenceLocator"))
                      if "purl" in rtype and loc:
                          purl=loc; break
                  res.append({"name":name,"version":version,"license":lic,"url":url,"purl":purl})
              return res
          def parse_cdx(doc):
              res=[]
              for c in doc.get("components") or []:
                  name=norm(c.get("name"))
                  if not name: continue
                  version=norm(c.get("version"))
                  purl=norm(c.get("purl"))
                  lic=None
                  if c.get("licenses"):
                      exprs=[norm(x.get("expression")) for x in c["licenses"] if isinstance(x,dict) and x.get("expression")]
                      if exprs and exprs[0]: lic=exprs[0]
                      else:
                          ids=[]
                          for entry in c["licenses"]:
                              licd=entry.get("license") if isinstance(entry,dict) else None
                              if isinstance(licd,dict):
                                  lid=norm(licd.get("id")); lname=norm(licd.get("name"))
                                  if lid: ids.append(lid)
                                  elif lname: ids.append(lname)
                          ids=sorted(set(ids))
                          lic=" AND ".join(ids) if ids else None
                  url=None
                  for ref in c.get("externalReferences") or []:
                      rtype=(ref.get("type") or "").lower(); u=norm(ref.get("url"))
                      if rtype in {"website","vcs","distribution","documentation","release-notes"} and u:
                          url=u; break
                  res.append({"name":name,"version":version,"license":lic,"url":url,"purl":purl})
              return res
          def slug(s: str, maxlen: int = 120) -> str:
              if not s: return "component"
              s = re.sub(r'["<>|*?:\\/\r\n]', '-', s)   # replace invalids with '-'
              s = re.sub(r'\s+', '-', s)
              s = re.sub(r'-{2,}', '-', s).strip('-')
              s = re.sub(r'[^A-Za-z0-9._-]+', '-', s)
              s = s[:maxlen].strip('-')
              return s or "component"
          sboms = os.environ.get("SBOMS","sboms/spdx-lite.json,sboms/cyclonedx.json").split(",")
          comps=[]
          for path in [s.strip() for s in sboms if s.strip()]:
              with open(path,"r",encoding="utf-8") as f:
                  doc=json.load(f)
              kind=detect(doc)
              if kind=="spdx": comps+=parse_spdx(doc)
              elif kind=="cdx": comps+=parse_cdx(doc)
          # de-dupe by purl else name@version
          merged={}
          for c in comps:
              key=("purl",c.get("purl")) if c.get("purl") else ("nv",f"{(c.get('name') or '').lower()}@{(c.get('version') or '').lower()}")
              if key not in merged: merged[key]=c
              else:
                  for fld in ("license","url","version"):
                      if not merged[key].get(fld) and c.get(fld): merged[key][fld]=c[fld]
          items=list(merged.values())
          matrix={"include":[]}
          for i,c in enumerate(items):
              base = c.get("purl") or c.get("name") or f"component-{i}"
              matrix["include"].append({
                  "idx": i,
                  "name": c.get("name") or "",
                  "version": c.get("version") or "",
                  "url": c.get("url") or "",
                  "purl": c.get("purl") or "",
                  "license": c.get("license") or "",
                  "safe_name": slug(base)
              })
          matrix_json=json.dumps(matrix, ensure_ascii=False)
          title=os.environ.get("TITLE","Open Source Notices")
          with open(os.environ["GITHUB_OUTPUT"],"a",encoding="utf-8") as out:
              out.write(f"matrix_json={matrix_json}\n")
              out.write(f"title={title}\n")
          PY
        env:
          SBOMS: "${{ github.event.inputs.sbom_paths || 'sboms/spdx-lite.json,sboms/cyclonedx.json' }}"
          TITLE: "${{ github.event.inputs.notice_title || 'Open Source Notices' }}"

      - name: Show matrix size (summary)
        run: |
          echo "### Prepared components for scanning" >> "$GITHUB_STEP_SUMMARY"
          python - <<'PY' >> "$GITHUB_STEP_SUMMARY"
          import json, os
          m=json.loads(os.environ["M"])
          print(f"- Title: **{os.environ['TITLE']}**")
          print(f"- Components to scan: **{len(m.get('include',[]))}**")
          PY
        env:
          M: ${{ steps.mk.outputs.matrix_json }}
          TITLE: ${{ steps.mk.outputs.title }}

  scan:
    needs: prepare
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.prepare.outputs.matrix_json) }}
      max-parallel: 12
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.idx }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install ScanCode Toolkit
        run: |
          python -m pip install --upgrade pip
          pip install scancode-toolkit requests packaging

      - name: Download source/archive for component
        id: dl
        run: |
          python - <<'PY'
          import os, re, requests, json
          from pathlib import Path

          REQ_TIMEOUT=45
          name=os.environ["NAME"]
          version=os.environ["VERSION"] or None
          purl=os.environ["PURL"] or None
          url=os.environ["URL"] or None
          safe=os.environ["SAFE_NAME"] or "component"

          work=Path(".scancode_work")/safe
          work.mkdir(parents=True, exist_ok=True)
          fn=None

          def get(url):
              r=requests.get(url,timeout=REQ_TIMEOUT)
              r.raise_for_status(); return r

          # --- PURL routing (same ecosystems as earlier) ---
          if purl and purl.startswith("pkg:npm/"):
              pkg=purl.split("/",2)[-1].split("@")[0]
              ver=version or (purl.split("@")[-1] if "@" in purl else None)
              meta=get(f"https://registry.npmjs.org/{pkg}/{ver or 'latest'}").json()
              tarball=meta["dist"]["tarball"]
              buf=get(tarball).content; fn=work/f"{pkg}-{ver or 'latest'}.tgz"; fn.write_bytes(buf)

          elif purl and purl.startswith("pkg:pypi/"):
              pkg=purl.split("/",2)[-1].split("@")[0]
              ver=version or (purl.split("@")[-1] if "@" in purl else None)
              u=f"https://pypi.org/pypi/{pkg}/{ver}/json" if ver else f"https://pypi.org/pypi/{pkg}/json"
              meta=get(u).json()
              urls=meta.get("urls",[])
              sdist=next((u for u in urls if u.get("packagetype")=="sdist"), None) or (urls[0] if urls else None)
              if sdist:
                  buf=get(sdist["url"]).content; fn=work/sdist["filename"]; fn.write_bytes(buf)

          elif purl and purl.startswith("pkg:maven/") and version:
              rest=purl[len("pkg:maven/"):]
              coords=rest.split("@")[0].split("/")
              if len(coords)>=2:
                  group,artifact=coords[0],coords[1]
                  base=f"https://repo1.maven.org/maven2/{group.replace('.','/')}/{artifact}/{version}"
                  for suffix in (f"{artifact}-{version}-sources.jar", f"{artifact}-{version}.jar"):
                      u=f"{base}/{suffix}"
                      r=requests.get(u,timeout=REQ_TIMEOUT)
                      if r.status_code==200:
                          fn=work/suffix; fn.write_bytes(r.content); break

          elif purl and purl.startswith("pkg:nuget/") and version:
              pkg=purl.split("/",2)[-1].split("@")[0]
              lower=pkg.lower()
              u=f"https://api.nuget.org/v3-flatcontainer/{lower}/{version}/{lower}.{version}.nupkg"
              r=requests.get(u,timeout=REQ_TIMEOUT)
              if r.status_code==200:
                  fn=work/f"{lower}.{version}.nupkg"; fn.write_bytes(r.content)

          elif purl and purl.startswith("pkg:gem/") and version:
              pkg=purl.split("/",2)[-1].split("@")[0]
              u=f"https://rubygems.org/downloads/{pkg}-{version}.gem"
              r=requests.get(u,timeout=REQ_TIMEOUT)
              if r.status_code==200:
                  fn=work/f"{pkg}-{version}.gem"; fn.write_bytes(r.content)

          elif purl and purl.startswith("pkg:golang/") and version:
              mod=purl[len("pkg:golang/"):].split("@")[0]
              u=f"https://proxy.golang.org/{mod}/@v/{version}.zip"
              r=requests.get(u,timeout=REQ_TIMEOUT)
              if r.status_code==200:
                  fn=work/f"{mod.replace('/','_')}@{version}.zip"; fn.write_bytes(r.content)

          # --- GitHub fallback (smarter) ---
          def try_codeload_zip(owner, repo, ref):
              u=f"https://codeload.github.com/{owner}/{repo}/zip/refs/heads/{ref}"
              r=requests.get(u,timeout=REQ_TIMEOUT)
              if r.status_code==200:
                  zf=work/f"{repo}-{ref}.zip"; zf.write_bytes(r.content); return zf
              return None

          def try_tag_zip(owner, repo, tag):
              u=f"https://codeload.github.com/{owner}/{repo}/zip/refs/tags/{tag}"
              r=requests.get(u,timeout=REQ_TIMEOUT)
              if r.status_code==200:
                  zf=work/f"{repo}-{tag}.zip"; zf.write_bytes(r.content); return zf
              return None

          if fn is None and url:
              m=re.match(r"https?://github\.com/([^/]+)/([^/?#]+)", url)
              if m:
                  owner, repo = m.group(1), m.group(2)
                  # 1) if version looks like a tag, try tag zip
                  if version and re.match(r"^[A-Za-z0-9._\-+/]+$", version):
                      fn = try_tag_zip(owner, repo, version)
                  # 2) try to discover default branch via GitHub API (unauthenticated)
                  if fn is None:
                      try:
                          api=f"https://api.github.com/repos/{owner}/{repo}"
                          r=requests.get(api, timeout=REQ_TIMEOUT)
                          if r.status_code==200:
                              default_branch=r.json().get("default_branch")
                              if default_branch:
                                  fn = try_codeload_zip(owner, repo, default_branch)
                      except Exception:
                          pass
                  # 3) try common branches
                  if fn is None:
                      for ref in ("HEAD","main","master","develop","stable","staging"):
                          fn = try_codeload_zip(owner, repo, ref)
                          if fn is not None: break

          # Export to GITHUB_OUTPUT
          with open(os.environ["GITHUB_OUTPUT"],"a") as out:
              out.write(f"archive={str(fn) if fn else ''}\n")
              out.write(f"workdir={str(work)}\n")
          PY
        env:
          NAME:      ${{ matrix.name }}
          VERSION:   ${{ matrix.version }}
          URL:       ${{ matrix.url }}
          PURL:      ${{ matrix.purl }}
          SAFE_NAME: ${{ matrix.safe_name }}

      - name: Extract archive
        id: ex
        if: steps.dl.outputs.archive != ''
        run: |
          python - <<'PY'
          import os, tarfile, zipfile
          from pathlib import Path
          arc = Path(os.environ["ARC"])
          out = Path(os.environ["WORK"]) / "src"
          out.mkdir(parents=True, exist_ok=True)
          ok=False
          try:
              if arc.suffix in (".tgz",".gz",".tar"):
                  with tarfile.open(arc,"r:*") as tf: tf.extractall(out); ok=True
              else:
                  with zipfile.ZipFile(arc) as zf: zf.extractall(out); ok=True
          except Exception:
              ok=False
          with open(os.environ["GITHUB_OUTPUT"],"a") as gh:
              gh.write(f"src={str(out) if ok else ''}\n")
          PY
        env:
          ARC:  ${{ steps.dl.outputs.archive }}
          WORK: ${{ steps.dl.outputs.workdir }}

      - name: Run ScanCode
        if: steps.ex.outputs.src != ''
        run: |
          scancode -cl --license-text --json-pp "${{ steps.dl.outputs.workdir }}/scan.json" "${{ steps.ex.outputs.src }}"

      - name: Write meta.json (name/version/url/license/purl)
        run: |
          python - <<'PY'
          import json, os
          from pathlib import Path
          meta = {
            "name": os.environ["NAME"],
            "version": os.environ["VERSION"],
            "url": os.environ["URL"],
            "license": os.environ["LICENSE"],
            "purl": os.environ["PURL"],
            "safe_name": os.environ["SAFE_NAME"]
          }
          wd=Path(os.environ["WORK"])
          (wd/"meta.json").write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")
          PY
        env:
          NAME:      ${{ matrix.name }}
          VERSION:   ${{ matrix.version }}
          URL:       ${{ matrix.url }}
          LICENSE:   ${{ matrix.license }}
          PURL:      ${{ matrix.purl }}
          SAFE_NAME: ${{ matrix.safe_name }}
          WORK:      ${{ steps.dl.outputs.workdir }}

      - name: Upload scan artifact (v4)
        uses: actions/upload-artifact@v4
        with:
          name: scan-${{ matrix.idx }}-${{ matrix.safe_name }}
          path: |
            ${{ steps.dl.outputs.workdir }}/scan.json
            ${{ steps.dl.outputs.workdir }}/meta.json
          if-no-files-found: warn

      - name: Job summary (component)
        run: |
          {
            echo "### Scan finished: ${{ matrix.name }} ${{ matrix.version }}";
            echo "- URL: ${{ matrix.url }}";
            echo "- PURL: \`${{ matrix.purl }}\`";
          } >> "$GITHUB_STEP_SUMMARY"

  merge:
    needs: [prepare, scan]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Download all scan artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: "scan-*"
          path: scans

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install helper libs
        run: |
          python -m pip install --upgrade pip
          pip install requests packaging

      - name: Build NOTICE.md from per-component scans
        id: build
        run: |
          python - <<'PY'
          import json, os
          from pathlib import Path

          title = "${{ needs.prepare.outputs.title }}"
          scans_dir = Path("scans")
          rows = []
          license_texts = {}

          for art_dir in scans_dir.iterdir():
              if not art_dir.is_dir(): continue
              scan = art_dir/"scan.json"
              meta = art_dir/"meta.json"
              if not scan.exists(): continue

              data = json.loads(scan.read_text(encoding="utf-8"))
              meta_d = {}
              if meta.exists():
                  meta_d = json.loads(meta.read_text(encoding="utf-8"))

              name    = meta_d.get("name") or art_dir.name
              version = meta_d.get("version") or ""
              url     = meta_d.get("url") or ""
              lic     = meta_d.get("license") or ""

              cps=[]
              ltexts={}
              for f in data.get("files",[]):
                  for cpr in f.get("copyrights",[]):
                      v=cpr.get("value")
                      if v: cps.append(v.strip())
                  for det in f.get("license_detections",[]):
                      key = det.get("license_expression_spdx") or det.get("license_expression") or det.get("license_key")
                      for m in det.get("matches",[]) or []:
                          t=(m.get("matched_text") or "").strip()
                          if t and key and key not in ltexts:
                              ltexts[key]=t

              seen=set(); cps_u=[]
              for ln in cps:
                  if ln not in seen:
                      seen.add(ln); cps_u.append(ln)

              rows.append({
                "name": name, "version": version, "url": url,
                "license": lic, "copyright": "\n".join(cps_u[:25])
              })
              for k,v in ltexts.items():
                  license_texts.setdefault(k, v)

          out=[]
          out.append(f"# {title}\n")
          for r in rows:
              out.append(f"### {r['name']}" + (f" {r['version']}" if r.get('version') else ""))
              if r.get("url"): out.append(f"- **URL:** {r['url']}")
              if r.get("license"): out.append(f"- **License:** {r['license']}")
              if r.get("copyright"):
                  out.append(f"- **Copyright:** {r['copyright']}")
              out.append("")

          if license_texts:
              out.append("\n## License Texts\n")
              for lid,text in sorted(license_texts.items()):
                  out.append(f"### {lid}\n```text\n{text.strip()}\n```\n")

          Path("NOTICE.md").write_text(("\n".join(out)).rstrip()+"\n", encoding="utf-8")
          with open(os.environ["GITHUB_OUTPUT"],"a") as gh:
              gh.write(f"count={len(rows)}\n")
          PY

      - uses: actions/upload-artifact@v4
        with:
          name: notice-md
          path: NOTICE.md

      - name: Commit NOTICE.md back (optional)
        if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
        run: |
          set -e
          if [ -f NOTICE.md ]; then
            git config user.name  "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add NOTICE.md
            git diff --cached --quiet || git commit -m "chore: update NOTICE.md (matrix ScanCode)"
            git push
          fi

      - name: Run summary
        run: |
          {
            echo "## NOTICE build summary";
            echo "- Components scanned: **${{ steps.build.outputs.count }}**";
            echo "- Parallel jobs used (max): **12**";
            echo "- See the **Artifacts** section for per-component scans and the merged NOTICE.md.";
          } >> "$GITHUB_STEP_SUMMARY"
