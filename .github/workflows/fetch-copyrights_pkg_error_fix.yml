name: Extract components & fetch copyrights pkg error fix

on:
  workflow_dispatch:
  push:
    branches: [ main, master ]
  pull_request:

permissions:
  contents: read
  id-token: none

concurrency:
  group: fetch-copyrights-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-and-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Validate SBOM files exist
        shell: bash
        run: |
          set -euo pipefail
          test -f "sboms/spdx-lite.json" || { echo "Missing sboms/spdx-lite.json" >&2; exit 1; }
          test -f "sboms/cyclonedx.json"  || { echo "Missing sboms/cyclonedx.json"  >&2; exit 1; }

      - name: Set up Python (3.11 for ScanCode 32.4.x)
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            requirements-scancode.txt

      - name: Create venv & install ScanCode (PyPI, pinned 32.4.1)
        id: install_scancode
        shell: bash
        run: |
          set -euo pipefail
          python -m venv .venv
          . .venv/bin/activate
          python -m pip install --upgrade pip
          echo 'scancode-toolkit==32.4.1' > requirements-scancode.txt
          pip install -r requirements-scancode.txt
          .venv/bin/scancode --version
          echo "SCANCODE=$GITHUB_WORKSPACE/.venv/bin/scancode" >> "$GITHUB_ENV"

      - name: Minimal OS packages
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y xz-utils bzip2 zlib1g libxml2-dev libxslt1-dev git-lfs
          git lfs install
          git config --global safe.directory "$GITHUB_WORKSPACE"

      # ========= Parse SBOMs → components.json (with license from SBOMs) =========
      - name: Generate components.json from SBOMs (component, version, git_url, license)
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, os, re, urllib.parse

          SPDX_PATH = "sboms/spdx-lite.json"
          CDX_PATH  = "sboms/cyclonedx.json"

          def load_json(path):
              if not os.path.exists(path): return None
              with open(path, 'r', encoding='utf-8') as f: return json.load(f)

          HOSTS = ("github.com", "gitlab.com", "bitbucket.org")

          def is_git_host(url: str|None) -> bool:
              if not url: return False
              u = url.strip().lower()
              return any(h in u for h in HOSTS) or u.startswith(("git://","git@","ssh://"))

          def normalize_git_url(url: str|None) -> str|None:
              """
              Accept only actual repo URLs (github.com/gitlab.com/bitbucket.org or git/ssh schemes).
              If url starts with 'pkg:' (purl), IGNORE it (return None).
              Ensure http(s) host URLs end with '.git'.
              """
              if not url: return None
              u = url.strip()
              if u.startswith("pkg:"):
                  return None  # hard rule: ignore purl always
              if not (u.startswith(("http://","https://","ssh://","git://","git@")) or is_git_host(u)):
                  return None
              if u.startswith(("http://","https://")) and any(h in u for h in HOSTS):
                  uu = u.rstrip("/")
                  if not uu.endswith(".git"):
                      uu += ".git"
                  return uu
              return u

          def last_segment(name: str|None):
              if not name: return None
              s = name
              for sep in ('/', ':'):
                  if sep in s: s = s.split(sep)[-1]
              return s

          def extract_from_purl(purl):
              """
              Only for component/version convenience; purl MUST NOT influence URL.
              Returns (component, version, NoneURL)
              """
              if not purl: return (None, None, None)
              s = purl.strip()
              if s.startswith("pkg:"): s = s[4:]
              s = s.split('#', 1)[0].split('?', 1)[0]
              version = None
              base = s
              if '@' in s:
                  base, version = s.rsplit('@', 1)
              component = urllib.parse.unquote(base.split('/')[-1])
              return (component, version, None)

          def pick_spdx_license_from_spdx(pkg) -> str|None:
              return (pkg.get("licenseConcluded") or pkg.get("licenseDeclared") or None)

          def pick_spdx_license_from_cdx(comp) -> str|None:
              for lic in comp.get("licenses", []) or []:
                  lobj = lic.get("license") or {}
                  spdx_id = lobj.get("id")
                  expr = lic.get("expression")
                  if expr: return expr
                  if spdx_id: return spdx_id
              return None

          def best_git_url_from_spdx(pkg) -> str|None:
              """
              DO NOT use/convert purl. Prefer real URLs present in SPDX:
              1) downloadLocation
              2) homepage
              3) externalRefs of type vcs/repository/scm (or any URL on known git hosts)
              """
              if not pkg: return None

              dl = pkg.get("downloadLocation") or ""
              u = normalize_git_url(dl)
              if u: return u

              hp = pkg.get("homepage") or ""
              u = normalize_git_url(hp)
              if u: return u

              for ref in pkg.get("externalRefs", []) or []:
                  rtype = (ref.get("referenceType") or ref.get("type") or "").lower()
                  loc = ref.get("referenceLocator") or ref.get("locator") or ""
                  if rtype in {"vcs","repository","scm"} or is_git_host(loc):
                      u = normalize_git_url(loc)
                      if u: return u

              return None

          def best_git_url_from_cdx(comp, purl) -> str|None:
              """
              DO NOT use/convert purl. For CycloneDX, prefer:
              - externalReferences of type vcs/repository/scm/source
              - component.repository
              """
              if comp:
                  for ref in comp.get("externalReferences", []) or []:
                      rtype = (ref.get("type") or "").lower()
                      url = ref.get("url") or ref.get("locator") or ""
                      if rtype in {"vcs","repository","scm","source"} or is_git_host(url):
                          u = normalize_git_url(url)
                          if u: return u

                  url = comp.get("repository") or ""
                  u = normalize_git_url(url)
                  if u: return u

              return None

          def parse_cyclonedx(path):
              out = []
              data = load_json(path)
              if not data: return out
              for c in data.get("components", []):
                  purl = c.get("purl")
                  name_p, ver_p, _git_p = extract_from_purl(purl) if purl else (None, None, None)
                  name     = name_p or last_segment(c.get("name"))
                  version  = (c.get("version") or ver_p)
                  version  = (None if not version or str(version).strip().lower() in {"", "unknown", "n/a", "na", "none"} else str(version).strip())
                  git_url  = normalize_git_url(best_git_url_from_cdx(c, purl))  # no purl fallback
                  license_ = pick_spdx_license_from_cdx(c)
                  if name:
                      out.append({"component": name, "version": version, "git_url": git_url, "license": license_})
              return out

          def parse_spdx(path):
              out = []
              data = load_json(path)
              if not data: return out
              pkgs = data.get("packages") or []
              for p in pkgs:
                  name    = last_segment(p.get("name") or p.get("packageName"))
                  version = p.get("versionInfo")
                  version = (None if not version or str(version).strip().lower() in {"", "unknown", "n/a", "na", "none"} else str(version).strip())

                  # Keep purl only for name/version convenience; not for URL
                  purl = None
                  for ref in p.get("externalRefs", []) or []:
                      rtype = (ref.get("referenceType") or ref.get("type") or "").lower()
                      loc   = ref.get("referenceLocator") or ref.get("locator") or ""
                      if rtype == "purl" and loc:
                          purl = loc
                          break

                  name_p, ver_p, _git_p = extract_from_purl(purl) if purl else (None, None, None)
                  if name_p: name = name_p
                  if not version and ver_p:
                      v = str(ver_p).strip()
                      version = (None if v.lower() in {"", "unknown", "n/a", "na", "none"} else v)

                  git_url  = normalize_git_url(best_git_url_from_spdx(p))  # no purl fallback
                  license_ = pick_spdx_license_from_spdx(p)
                  if name:
                      out.append({"component": name, "version": version, "git_url": git_url, "license": license_})
              return out

          # Parse & merge
          comps  = parse_cyclonedx(CDX_PATH) + parse_spdx(SPDX_PATH)
          merged = {}
          for c in comps:
              key = (c["component"], c.get("version") or "")
              prev = merged.get(key)
              if not prev:
                  merged[key] = c
              else:
                  if not prev.get("license") and c.get("license"):
                      prev["license"] = c["license"]
                  if not prev.get("git_url") and c.get("git_url"):
                      prev["git_url"] = c["git_url"]

          result = list(merged.values())
          os.makedirs("artifacts", exist_ok=True)
          with open("artifacts/components.json", "w", encoding="utf-8") as f:
              json.dump({"components": result}, f, indent=2, ensure_ascii=False)
          print(f"Wrote artifacts/components.json with {len(result)} components.")

          # Optional: warn if any component lacks a real git_url
          missing = [c["component"] for c in result if not c.get("git_url")]
          if missing:
              print("WARNING: No git_url found for components:", ", ".join(missing))
          PY

      - name: Upload components.json
        uses: actions/upload-artifact@v4
        with:
          name: components-json
          path: artifacts/components.json

      # ========= Clone & Scan =========
      - name: Clone repos and run ScanCode (copyright + license)
        env:
          SCANCODE: ${{ env.SCANCODE }}
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, os, subprocess, shlex, re

          SCANCODE = os.environ["SCANCODE"]

          with open("artifacts/components.json", "r", encoding="utf-8") as f:
              comps = json.load(f).get("components", [])

          os.makedirs("repos", exist_ok=True)
          os.makedirs("scancode_results", exist_ok=True)

          def sanitize(s):
              return re.sub(r'[^A-Za-z0-9_.-]+', '-', (s or "")).strip('-') or "unknown"

          def run(cmd):
              print("+", cmd)
              return subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)

          for item in comps:
              name    = item.get("component")
              version = item.get("version")  # None => default branch
              git_url = item.get("git_url")

              out_json = os.path.join("scancode_results", sanitize(name) + ".json")

              if not name or not git_url:
                  with open(out_json, "w", encoding="utf-8") as f:
                      json.dump({"files": [], "status": "skipped:no-git-url"}, f)
                  continue

              dest = os.path.join("repos", sanitize(name) + (f"-{sanitize(version)}" if version else ""))

              if not os.path.exists(dest):
                  ok = False
                  if version:
                      p = run(f"git clone --depth 1 --branch {shlex.quote(str(version))} {shlex.quote(git_url)} {shlex.quote(dest)}")
                      ok = (p.returncode == 0)
                      if not ok:
                          print(p.stdout)
                          # Fallback: shallow fetch ref into FETCH_HEAD then checkout
                          p = run(f"git clone --no-checkout --depth 1 {shlex.quote(git_url)} {shlex.quote(dest)}")
                          if p.returncode == 0:
                              cwd = os.getcwd()
                              os.chdir(dest)
                              p = run(f"git -c advice.detachedHead=false fetch --depth 1 origin {shlex.quote(str(version))}:FETCH_HEAD")
                              if p.returncode == 0:
                                  p = run("git checkout --detach FETCH_HEAD")
                                  ok = (p.returncode == 0)
                              os.chdir(cwd)
                          if not ok and p:
                              print(p.stdout)

                  if not ok and not version:
                      p = run(f"git clone --depth 1 {shlex.quote(git_url)} {shlex.quote(dest)}")
                      ok = (p.returncode == 0)
                      if not ok: print(p.stdout)

                  if not ok:
                      with open(out_json, "w", encoding="utf-8") as f:
                          json.dump({"files": [], "status": "skipped:clone-failed"}, f)
                      continue

              cmd = f"{shlex.quote(SCANCODE)} --copyright --license --strip-root --json-pp {shlex.quote(out_json)} {shlex.quote(dest)}"
              p = run(cmd)
              if p.returncode != 0:
                  print(p.stdout)
          PY

      - name: Upload raw ScanCode outputs (per-repo)
        uses: actions/upload-artifact@v4
        with:
          name: scancode-raw
          path: scancode_results
          if-no-files-found: ignore
          retention-days: 7

      # ========= Aggregate copyrights (JSON)
      - name: Aggregate copyrights (JSON)
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, os, re

          with open("artifacts/components.json", "r", encoding="utf-8") as f:
              comps = json.load(f).get("components", [])

          def sanitize(s):
              return re.sub(r'[^A-Za-z0-9_.-]+', '-', (s or "")).strip('-') or "unknown"

          def load_raw(component_name):
              p = os.path.join("scancode_results", sanitize(component_name) + ".json")
              if os.path.exists(p):
                  with open(p, "r", encoding="utf-8") as f:
                      return json.load(f)
              return {"files": [], "status": "skipped:no-scan"}

          results = []
          for item in comps:
              name     = item.get("component")
              version  = item.get("version")
              git_url  = item.get("git_url")
              sbom_lic = item.get("license")
              data     = load_raw(name)

              unique = set()
              per_file = []
              for fe in data.get("files", []) or []:
                  path = fe.get("path") or fe.get("location") or ""
                  file_statements, holders = [], []

                  for c in fe.get("copyrights", []) or []:
                      single = (c.get("copyright") or "").strip()
                      if single:
                          file_statements.append(single)
                          unique.add(single)
                      for s in c.get("statements", []) or []:
                          s = (s or "").strip()
                          if s:
                              file_statements.append(s)
                              unique.add(s)
                      for h in c.get("holders", []) or []:
                          h = (h or "").strip()
                          if h:
                              holders.append(h)

                  for a in fe.get("authors", []) or []:
                      author = (a.get("author") or "").strip()
                      if author:
                          file_statements.append(author)
                          unique.add(author)

                  if file_statements or holders:
                      per_file.append({
                          "path": path,
                          "statements": file_statements,
                          "holders": holders
                      })

              results.append({
                  "component": name,
                  "version": version,
                  "git_url": git_url,
                  "license": sbom_lic,   # SBOM license only
                  "status": data.get("status", "scanned"),
                  "copyrights": {
                      "unique_statements": sorted(unique),
                      "per_file": per_file
                  }
              })

          os.makedirs("artifacts", exist_ok=True)
          with open("artifacts/component_copyrights.json", "w", encoding="utf-8") as f:
              json.dump({"components": results}, f, indent=2, ensure_ascii=False)

          print(f"Wrote artifacts/component_copyrights.json for {len(results)} components.")
          PY

      - name: Upload aggregated copyrights (JSON)
        uses: actions/upload-artifact@v4
        with:
          name: component-copyrights
          path: artifacts/component_copyrights.json
          if-no-files-found: error
          retention-days: 30

      # ========= Attribution (YAML)
      - name: Build per-component attribution (YAML)
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, os, re

          with open("artifacts/components.json", "r", encoding="utf-8") as f:
              components = json.load(f).get("components", [])

          with open("artifacts/component_copyrights.json", "r", encoding="utf-8") as f:
              agg = json.load(f).get("components", [])

          by_name = {c.get("component"): c for c in agg}

          def esc(s: str|None):
              if s is None: return '""'
              if re.search(r'[:#\-\[\]{},&*?]|^\s|\s$', s):
                  return '"' + s.replace('"', '\\"') + '"'
              return s

          lines = []
          lines.append("components:")
          for comp in components:
              name   = comp.get("component")
              version= comp.get("version")
              url    = comp.get("git_url") or ""
              lic    = comp.get("license") or ""    # SBOM license only

              lines.append(f"  - component: {esc(name)}")
              if version is not None:
                  lines.append(f"    version: {esc(version)}")
              lines.append(f"    url: {esc(url)}")
              lines.append(f"    license: {esc(lic)}")

              cps = (by_name.get(name, {}) or {}).get("copyrights", {}).get("unique_statements", []) or []
              if cps:
                  lines.append("    copyrights:")
                  for c in cps:
                      lines.append(f"      - {esc(c)}")
              else:
                  lines.append("    copyrights: []")

          os.makedirs("artifacts", exist_ok=True)
          out_yaml = "artifacts/component_attribution.yaml"
          with open(out_yaml, "w", encoding="utf-8") as f:
              f.write("\n".join(lines) + "\n")
          print(f"Wrote {out_yaml} with {len(components)} components.")
          PY

      - name: Upload per-component attribution (YAML)
        uses: actions/upload-artifact@v4
        with:
          name: component-attribution
          path: artifacts/component_attribution.yaml
          if-no-files-found: error
          retention-days: 30

      # ========= Attribution (TXT)
      - name: Build per-component attribution (TXT)
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, os

          with open("artifacts/components.json", "r", encoding="utf-8") as f:
              components = json.load(f).get("components", [])

          with open("artifacts/component_copyrights.json", "r", encoding="utf-8") as f:
              agg = json.load(f).get("components", [])

          by_name = {c.get("component"): c for c in agg}

          lines = []
          for comp in components:
              name    = comp.get("component") or ""
              version = comp.get("version")
              url     = comp.get("git_url") or ""
              lic     = comp.get("license") or ""  # SBOM license only

              lines.append(f"Component: {name}")
              if version:
                  lines.append(f"Version: {version}")
              lines.append(f"URL: {url}")
              lines.append(f"License: {lic}")

              lines.append("Copyrights:")
              cps = (by_name.get(name, {}) or {}).get("copyrights", {}).get("unique_statements", []) or []
              if cps:
                  for stmt in cps:
                      lines.append(f"- {stmt}")
              else:
                  lines.append("- (none)")
              lines.append("")

          os.makedirs("artifacts", exist_ok=True)
          out_txt = "artifacts/component_attribution.txt"
          with open(out_txt, "w", encoding="utf-8") as f:
              f.write("\n".join(lines).rstrip() + "\n")
          print(f"Wrote {out_txt} with {len(components)} components.")
          PY

      - name: Upload per-component attribution (TXT)
        uses: actions/upload-artifact@v4
        with:
          name: component-attribution-text
          path: artifacts/component_attribution.txt
          if-no-files-found: error
          retention-days: 30

      # ========= Job summary =========
      - name: Summarize results
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          echo "### Component Scan Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- components.json ✅" >> $GITHUB_STEP_SUMMARY
          echo "- component_copyrights.json ✅" >> $GITHUB_STEP_SUMMARY
          echo "- component_attribution.yaml ✅" >> $GITHUB_STEP_SUMMARY
          echo "- component_attribution.txt ✅" >> $GITHUB_STEP_SUMMARY
